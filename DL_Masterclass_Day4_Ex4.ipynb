{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_Masterclass_Day4_Ex4.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"zIuMh-AArL78","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":910},"outputId":"e6eb2d14-ffdd-431e-c089-3ec1ab8d643d","executionInfo":{"status":"ok","timestamp":1567089084682,"user_tz":-120,"elapsed":1840021,"user":{"displayName":"ananya neogi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDaXX5hpTJBdR7jrnLKxnXHfnsCyNveb4DMLEkB-A=s64","userId":"00462567981712017677"}}},"source":["'''Trains a simple convnet on the MNIST dataset.\n","Gets to 99.25% test accuracy after 12 epochs\n","(there is still a lot of margin for parameter tuning).\n","16 seconds per epoch on a GRID K520 GPU.\n","'''\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 12\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0829 14:00:46.811416 140596197640064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0829 14:00:46.828898 140596197640064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0829 14:00:46.833440 140596197640064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0829 14:00:46.873646 140596197640064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","W0829 14:00:46.879501 140596197640064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0829 14:00:46.888831 140596197640064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0829 14:00:46.957624 140596197640064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0829 14:00:46.966455 140596197640064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n"],"name":"stdout"},{"output_type":"stream","text":["W0829 14:00:47.059056 140596197640064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/12\n","60000/60000 [==============================] - 154s 3ms/step - loss: 0.2630 - acc: 0.9196 - val_loss: 0.0577 - val_acc: 0.9817\n","Epoch 2/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0870 - acc: 0.9738 - val_loss: 0.0405 - val_acc: 0.9861\n","Epoch 3/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0642 - acc: 0.9808 - val_loss: 0.0321 - val_acc: 0.9889\n","Epoch 4/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0532 - acc: 0.9839 - val_loss: 0.0308 - val_acc: 0.9895\n","Epoch 5/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0458 - acc: 0.9862 - val_loss: 0.0280 - val_acc: 0.9901\n","Epoch 6/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0408 - acc: 0.9875 - val_loss: 0.0271 - val_acc: 0.9901\n","Epoch 7/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0363 - acc: 0.9894 - val_loss: 0.0276 - val_acc: 0.9918\n","Epoch 8/12\n","60000/60000 [==============================] - 153s 3ms/step - loss: 0.0348 - acc: 0.9893 - val_loss: 0.0262 - val_acc: 0.9915\n","Epoch 9/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0326 - acc: 0.9896 - val_loss: 0.0266 - val_acc: 0.9910\n","Epoch 10/12\n","60000/60000 [==============================] - 153s 3ms/step - loss: 0.0287 - acc: 0.9912 - val_loss: 0.0283 - val_acc: 0.9914\n","Epoch 11/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0297 - acc: 0.9908 - val_loss: 0.0290 - val_acc: 0.9908\n","Epoch 12/12\n","60000/60000 [==============================] - 152s 3ms/step - loss: 0.0263 - acc: 0.9918 - val_loss: 0.0267 - val_acc: 0.9908\n","Test loss: 0.026722431118016175\n","Test accuracy: 0.9908\n"],"name":"stdout"}]}]}